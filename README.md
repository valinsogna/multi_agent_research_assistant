# ğŸ”¬ Multi-Agent Research Assistant

Un sistema multi-agente con protoclli **MCP** (Model Context Protocol) e **A2A** (Agent-to-Agent) per eseguire ricerche web, analizzare documenti e generare report sintetici usando modelli di linguaggio locali (es. DeepSeek via Ollama).

## ğŸ¯ Technolgie

| Requisito | Come |
|---------------------|---------------------|
| Agentic System design | 3 agenti specializzati che collaborano |
| MCP experience | Server MCP custom per web search e file analysis |
| A2A understanding | Protocollo di comunicazione tra agenti |
| GenAI technologies | DeepSeek/Llama locale via Ollama |
| Testing agentic systems | Framework di valutazione incluso |
| LangChain/LlamaIndex | Orchestrazione con LangGraph |

## ğŸ—ï¸ Architettura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ORCHESTRATOR AGENT                           â”‚
â”‚                  (Coordina il workflow)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚               â”‚               â”‚
              â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RESEARCH AGENT â”‚ â”‚  ANALYSIS AGENT â”‚ â”‚  SYNTHESIS AGENTâ”‚
â”‚                 â”‚ â”‚                 â”‚ â”‚                 â”‚
â”‚ â€¢ Web Search    â”‚ â”‚ â€¢ Doc Processingâ”‚ â”‚ â€¢ Report Gen    â”‚
â”‚ â€¢ News Fetch    â”‚ â”‚ â€¢ Data Extract  â”‚ â”‚ â€¢ Summarization â”‚
â”‚ â€¢ Source Rank   â”‚ â”‚ â€¢ Fact Check    â”‚ â”‚ â€¢ Citations     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚                   â”‚
         â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MCP TOOL SERVERS                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Web Search   â”‚  â”‚ File Reader  â”‚  â”‚ Report Writerâ”‚          â”‚
â”‚  â”‚ (DuckDuckGo) â”‚  â”‚ (PDF/TXT)    â”‚  â”‚ (Markdown)   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Prerequisiti

- Python 3.10+
- 8GB+ RAM (per modelli locali)
- ~10GB spazio disco (per Ollama + modelli)

---

## ğŸš€ Setup Completo

### Step 1: Installa Ollama (per LLM locale)

```bash
# Linux
curl -fsSL https://ollama.com/install.sh | sh

# macOS
brew install ollama

# Windows: scarica da https://ollama.com/download
```

### Step 2: Scarica DeepSeek (o alternativa)

```bash
# Opzione 1: DeepSeek R1 (consigliato, ~4GB)
ollama pull deepseek-r1:7b

# Opzione 2: Llama 3.2 (piÃ¹ leggero, ~2GB)
ollama pull llama3.2:3b

# Opzione 3: Qwen 2.5 (buon bilanciamento)
ollama pull qwen2.5:7b

# Verifica che funzioni
ollama run deepseek-r1:7b "Ciao, rispondi brevemente"
```

### Step 3: Crea l'ambiente Conda

```bash
# Crea ambiente
conda create -n aissistant python=3.11 -y

# Attiva
conda activate aissistant
```

### Step 4: Installa le dipendenze

```bash
# Clona/entra nella cartella del progetto
cd multi_agent_research_assistant

# Installa tutto
pip install -r requirements.txt
```

---

## ğŸ“¦ Struttura del Progetto

```
multi_agent_research_assistant/
â”œâ”€â”€ README.md                    # Questa guida
â”œâ”€â”€ requirements.txt             # Dipendenze Python
â”œâ”€â”€ config.py                    # Configurazione centralizzata
â”‚
â”œâ”€â”€ mcp_servers/                 # Server MCP (Tool)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ web_search_mcp.py       # Tool per ricerca web
â”‚   â”œâ”€â”€ file_reader_mcp.py      # Tool per leggere documenti
â”‚   â””â”€â”€ report_writer_mcp.py    # Tool per generare report
â”‚
â”œâ”€â”€ agents/                      # Agenti specializzati
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_agent.py           # Classe base
â”‚   â”œâ”€â”€ research_agent.py       # Agente ricerca
â”‚   â”œâ”€â”€ analysis_agent.py       # Agente analisi
â”‚   â””â”€â”€ synthesis_agent.py      # Agente sintesi
â”‚
â”œâ”€â”€ orchestrator/                # Coordinamento A2A
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ workflow.py             # LangGraph workflow
â”‚   â””â”€â”€ state.py                # Stato condiviso
â”‚
â”œâ”€â”€ tests/                       # Test e valutazione
â”‚   â”œâ”€â”€ test_mcp_servers.py
â”‚   â”œâ”€â”€ test_agents.py
â”‚   â””â”€â”€ evaluation.py
â”‚
â””â”€â”€ examples/                    # Esempi d'uso
    â”œâ”€â”€ financial_research.py   # Caso d'uso bancario
    â””â”€â”€ market_analysis.py      # Analisi di mercato
```

---

## ğŸƒ Quick Start

```bash
# 1. Attiva ambiente
conda activate aissistant

# 2. Avvia Ollama (in un terminale separato)
ollama serve

# 3. Esegui esempio
python examples/financial_research.py
```

---

## ğŸ’¡ Punti da Evidenziare

1. **Design Pattern A2A**: Gli agenti comunicano tramite uno stato condiviso tipizzato
2. **MCP Standard**: I tool seguono il protocollo MCP ufficiale di Anthropic
3. **ScalabilitÃ **: Architettura modulare, facile aggiungere nuovi agenti/tool
4. **Testing**: Framework di valutazione per misurare performance
5. **Local-First**: Funziona senza API costose (DeepSeek locale)
6. **Enterprise-Ready**: Pattern applicabili a use case bancari

---

## ğŸ“š Documentazione Aggiuntiva

- [MCP Protocol](https://modelcontextprotocol.io/)
- [LangGraph](https://langchain-ai.github.io/langgraph/)
- [Ollama](https://ollama.com/)
- [DeepSeek](https://deepseek.com/)
