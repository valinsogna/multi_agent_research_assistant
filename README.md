# ğŸ”¬ Multi-Agent Research Assistant

Un sistema multi-agente con protoclli **MCP** (Model Context Protocol) per eseguire ricerche web, analizzare documenti e generare report sintetici usando modelli di linguaggio locali (es. DeepSeek via Ollama).

## ğŸ¯ Technolgie

| Requisito | Come |
|---------------------|---------------------|
| Agentic System design | 3 agenti specializzati che collaborano |
| MCP experience | Server MCP custom per web search e file analysis |
| A2A understanding | Protocollo di comunicazione tra agenti |
| GenAI technologies | DeepSeek/Llama locale via Ollama |
| Testing agentic systems | Framework di valutazione incluso |
| LangChain/LlamaIndex | Orchestrazione con LangGraph |

## ğŸ—ï¸ Architettura

> ğŸ“– Per documentazione dettagliata vedi [Q&As/ARCHITECTURE.md](./Q&As/ARCHITECTURE.md)

### Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      LANGGRAPH ORCHESTRATOR                             â”‚
â”‚                   (Codice Python deterministico)                        â”‚
â”‚                                                                         â”‚
â”‚   ResponsabilitÃ :                                                       â”‚
â”‚   â€¢ Esegue i nodi in sequenza                                           â”‚
â”‚   â€¢ Gestisce lo stato condiviso                                         â”‚
â”‚   â€¢ Decide quando fermarsi (errore/successo)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                         Flusso SEQUENZIALE
                                    â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                             â”‚                             â”‚
      â–¼                             â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1   â”‚                â”‚  STEP 2   â”‚                â”‚  STEP 3   â”‚
â”‚ RESEARCH  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚ ANALYSIS  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚ SYNTHESIS â”‚
â”‚  AGENT    â”‚                â”‚   AGENT   â”‚                â”‚   AGENT   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                             â”‚                             â”‚
      â–¼                             â–¼                             â–¼
  Trova info                  Struttura                      Genera
  (web + news)                i dati                        report
```

### Dettaglio Agenti

| Agente | ResponsabilitÃ  | Input | Output | Chiamate LLM |
|--------|---------------|-------|--------|--------------|
| **ğŸ” Research** | Cercare informazioni grezze | Query utente | 10 web results + 5 news | 1 |
| **ğŸ”¬ Analysis** | Estrarre pattern e insight | research_results (troncato) | JSON con temi, trend, lacune | 1 |
| **ğŸ“ Synthesis** | Creare report professionale | research + analysis results | File Markdown/HTML | 2 |

### Flusso Dati e Protezione Context Window

```
USER INPUT: "AI nel settore bancario"
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RESEARCH AGENT                                                          â”‚
â”‚                                                                         â”‚
â”‚ â€¢ Genera 3 varianti query: 2 di default e 1 opzionale.                  â”‚    
â”‚ â€¢ Web search: 2 query di default Ã— 5 risultati = 10 totali              â”‚
â”‚ â€¢ News search: 5 risultati (ultima settimana)                           â”‚
â”‚ â€¢ 1 chiamata LLM per analisi preliminare                                â”‚
â”‚                                                                         â”‚
â”‚ OUTPUT: ~10 web results + 5 news + analisi preliminare                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚  âš ï¸ TRONCAMENTO (protezione context window)
                    â”‚  â€¢ Max 5 web results (di 10)
                    â”‚  â€¢ Max 200 char per fonte
                    â”‚  â€¢ Max 3 news (di 5)
                    â”‚  â€¢ TOTALE: ~3000 char (~800 token)
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ANALYSIS AGENT                                                          â”‚
â”‚                                                                         â”‚
â”‚ â€¢ Riceve dati TRONCATI (non tutto l'output di Research)                â”‚
â”‚ â€¢ 1 chiamata LLM con prompt strutturato                                â”‚
â”‚ â€¢ Output: JSON con temi, trend, lacune, contraddizioni                 â”‚
â”‚                                                                         â”‚
â”‚ OUTPUT: { temi: [...], trend: "...", lacune: [...] }                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SYNTHESIS AGENT                                                         â”‚
â”‚                                                                         â”‚
â”‚ â€¢ Riceve research_results + analysis_results                           â”‚
â”‚ â€¢ 2 chiamate LLM: sezioni + executive summary                          â”‚
â”‚ â€¢ Assembla report con indice, fonti, metadata                          â”‚
â”‚ â€¢ Salva file in outputs/                                               â”‚
â”‚                                                                         â”‚
â”‚ OUTPUT: outputs/report_xxx.md                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Comunicazione tra Agenti (Pattern Blackboard)

Gli agenti **NON comunicano direttamente**. Leggono/scrivono su uno stato condiviso:

```python
# WorkflowState - la "lavagna" condivisa
{
    "query": "AI settore bancario",           # Input utente
    "research_results": {...},                 # â† Scritto da Research Agent
    "analysis_results": {...},                 # â† Scritto da Analysis Agent
    "synthesis_results": {...},                # â† Scritto da Synthesis Agent
    "status": "COMPLETED",
    "agent_history": [...]                     # Log esecuzione
}
```

Ogni agente:
- âœ… LEGGE dallo stato ciÃ² che gli serve
- âœ… SCRIVE nello stato il suo output
- âŒ NON parla direttamente con altri agenti
- âŒ NON mantiene memoria delle chiamate precedenti

---

## ğŸ“‹ Prerequisiti

- Python 3.10+
- 8GB+ RAM (per modelli locali)
- ~10GB spazio disco (per Ollama + modelli)

---

## ğŸš€ Setup Completo

### Step 1: Installa Ollama (per LLM locale)

```bash
# Linux
curl -fsSL https://ollama.com/install.sh | sh

# macOS
brew install ollama

# Windows: scarica da https://ollama.com/download
```

### Step 2: Scarica DeepSeek (o alternativa)

```bash
# Opzione 1: DeepSeek R1 (consigliato, ~4GB)
ollama pull deepseek-r1:7b

# Opzione 2: Llama 3.2 (piÃ¹ leggero, ~2GB)
ollama pull llama3.2:3b

# Opzione 3: Qwen 2.5 (buon bilanciamento)
ollama pull qwen2.5:7b

# Verifica che funzioni
ollama run deepseek-r1:7b "Ciao, rispondi brevemente"
```

### Step 3: Crea l'ambiente Conda

```bash
# Crea ambiente
conda create -n aissistant python=3.11 -y

# Attiva
conda activate aissistant
```

### Step 4: Installa le dipendenze

```bash
# Clona/entra nella cartella del progetto
cd multi_agent_research_assistant

# Installa tutto
pip install -r requirements.txt
```

---

## ğŸ“¦ Struttura del Progetto

```
multi_agent_research_assistant/
â”œâ”€â”€ README.md                    # Questa guida
â”œâ”€â”€ requirements.txt             # Dipendenze Python
â”œâ”€â”€ config.py                    # Configurazione centralizzata
â”‚
â”œâ”€â”€ mcp_servers/                 # Server MCP (Tool)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ web_search_mcp.py       # Tool per ricerca web
â”‚   â”œâ”€â”€ file_reader_mcp.py      # Tool per leggere documenti
â”‚   â””â”€â”€ report_writer_mcp.py    # Tool per generare report
â”‚
â”œâ”€â”€ agents/                      # Agenti specializzati
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_agent.py           # Classe base
â”‚   â”œâ”€â”€ research_agent.py       # Agente ricerca
â”‚   â”œâ”€â”€ analysis_agent.py       # Agente analisi
â”‚   â””â”€â”€ synthesis_agent.py      # Agente sintesi
â”‚
â”œâ”€â”€ orchestrator/                # Coordinamento A2A
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ workflow.py             # LangGraph workflow
â”‚   â””â”€â”€ state.py                # Stato condiviso
â”‚
â”œâ”€â”€ tests/                       # Test e valutazione
â”‚   â”œâ”€â”€ test_mcp_servers.py
â”‚   â”œâ”€â”€ test_agents.py
â”‚   â””â”€â”€ evaluation.py
â”‚
â””â”€â”€ examples/                    # Esempi d'uso
    â”œâ”€â”€ financial_research.py   # Caso d'uso bancario
    â””â”€â”€ market_analysis.py      # Analisi di mercato
```

---

## ğŸƒ Quick Start

```bash
# 1. Attiva ambiente
conda activate aissistant

# 2. Avvia Ollama (in un terminale separato)
ollama serve

# 3. Esegui esempio
python examples/financial_research.py
```

---

## ğŸ’¡ Punti da Evidenziare

1. **Design Pattern A2A**: Gli agenti comunicano tramite uno stato condiviso tipizzato
2. **MCP Standard**: I tool seguono il protocollo MCP ufficiale di Anthropic
3. **ScalabilitÃ **: Architettura modulare, facile aggiungere nuovi agenti/tool
4. **Testing**: Framework di valutazione per misurare performance
5. **Local-First**: Funziona senza API costose (DeepSeek locale)
6. **Enterprise-Ready**: Pattern applicabili a use case bancari

---

## ğŸ“š Documentazione Aggiuntiva

- [MCP Protocol](https://modelcontextprotocol.io/)
- [LangGraph](https://langchain-ai.github.io/langgraph/)
- [Ollama](https://ollama.com/)
- [DeepSeek](https://deepseek.com/)
